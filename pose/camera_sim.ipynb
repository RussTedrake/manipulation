{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EgiF12Hf1Dhs"
   },
   "source": [
    "This notebook provides examples to go along with the [textbook](http://manipulation.csail.mit.edu/pose.html).  I recommend having both windows open, side-by-side!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eeMrMI0-1Dhu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpld3\n",
    "import numpy as np\n",
    "import pydot\n",
    "from IPython.display import HTML, SVG, display\n",
    "from pydrake.all import (AbstractValue, AddMultibodyPlantSceneGraph, BaseField,\n",
    "                         ConstantValueSource, DepthImageToPointCloud,\n",
    "                         DiagramBuilder, FindResourceOrThrow,\n",
    "                         MeshcatPointCloudVisualizer, MeshcatVisualizer,\n",
    "                         MeshcatVisualizerParams, Parser, PointCloud,\n",
    "                         RigidTransform, RollPitchYaw, RotationMatrix,\n",
    "                         StartMeshcat)\n",
    "\n",
    "from manipulation import running_as_notebook\n",
    "from manipulation.scenarios import (AddMultibodyTriad, AddRgbdSensor,\n",
    "                                    MakeManipulationStation)\n",
    "from manipulation.utils import FindResource\n",
    "\n",
    "if running_as_notebook:\n",
    "    mpld3.enable_notebook()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the visualizer.\n",
    "meshcat = StartMeshcat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7q0A14bAilIX"
   },
   "source": [
    "# Simulating an RGB-D camera\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILYLouFTjv6e"
   },
   "outputs": [],
   "source": [
    "def DepthCameraDemoSystem():\n",
    "    builder = DiagramBuilder()\n",
    "\n",
    "    # Create the physics engine + scene graph.\n",
    "    plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.0)\n",
    "    # Add a single object into it.\n",
    "    X_Mustard = RigidTransform(RollPitchYaw(-np.pi/2., 0, -np.pi/2.), [0, 0, 0.09515])\n",
    "    parser = Parser(plant)\n",
    "    mustard = parser.AddModelFromFile(FindResourceOrThrow(\n",
    "        \"drake/manipulation/models/ycb/sdf/006_mustard_bottle.sdf\"))\n",
    "    plant.WeldFrames(plant.world_frame(), \n",
    "                     plant.GetFrameByName(\"base_link_mustard\", mustard), \n",
    "                     X_Mustard)\n",
    "\n",
    "    # Add a box for the camera in the environment.\n",
    "    X_Camera = RigidTransform(\n",
    "        RollPitchYaw(0, -0.2, 0.2).ToRotationMatrix().multiply(\n",
    "            RollPitchYaw(-np.pi/2.0, 0, np.pi/2.0).ToRotationMatrix()),\n",
    "        [.5, .1, .2])\n",
    "    camera_instance = parser.AddModelFromFile(FindResource(\"models/camera_box.sdf\"))\n",
    "    camera_frame = plant.GetFrameByName(\"base\", camera_instance)    \n",
    "    plant.WeldFrames(plant.world_frame(), camera_frame, X_Camera)\n",
    "    AddMultibodyTriad(camera_frame, scene_graph, length=.1, radius=0.005)\n",
    "    plant.Finalize()\n",
    "\n",
    "    params = MeshcatVisualizerParams()\n",
    "#    params.delete_on_initialization_event = False\n",
    "    visualizer = MeshcatVisualizer.AddToBuilder(\n",
    "        builder, scene_graph, meshcat, params)\n",
    "\n",
    "    camera = AddRgbdSensor(builder, scene_graph, X_PC=RigidTransform(),\n",
    "                           parent_frame_id=plant.GetBodyFrameIdOrThrow(\n",
    "                               camera_frame.body().index()))\n",
    "    camera.set_name(\"rgbd_sensor\")\n",
    "\n",
    "    # Export the camera outputs\n",
    "    builder.ExportOutput(camera.color_image_output_port(), \"color_image\")\n",
    "    builder.ExportOutput(camera.depth_image_32F_output_port(), \"depth_image\")\n",
    "\n",
    "    # Add a system to convert the camera output into a point cloud\n",
    "    to_point_cloud = builder.AddSystem(\n",
    "        DepthImageToPointCloud(camera_info=camera.depth_camera_info(),\n",
    "                               fields=BaseField.kXYZs | BaseField.kRGBs))\n",
    "    builder.Connect(camera.depth_image_32F_output_port(),\n",
    "                    to_point_cloud.depth_image_input_port())\n",
    "    builder.Connect(camera.color_image_output_port(),\n",
    "                    to_point_cloud.color_image_input_port())\n",
    "\n",
    "    # Send the point cloud to meshcat for visualization, too.\n",
    "    point_cloud_visualizer = builder.AddSystem(\n",
    "        MeshcatPointCloudVisualizer(meshcat, \"cloud\"))\n",
    "    builder.Connect(to_point_cloud.point_cloud_output_port(),\n",
    "                    point_cloud_visualizer.cloud_input_port())\n",
    "    camera_pose = builder.AddSystem(\n",
    "        ConstantValueSource(AbstractValue.Make(X_Camera)))\n",
    "    builder.Connect(camera_pose.get_output_port(),\n",
    "                    point_cloud_visualizer.pose_input_port())\n",
    "\n",
    "    # Export the point cloud output.\n",
    "    builder.ExportOutput(to_point_cloud.point_cloud_output_port(),\n",
    "                         \"point_cloud\")\n",
    "\n",
    "    diagram = builder.Build()\n",
    "    diagram.set_name(\"depth_camera_demo_system\")\n",
    "    return diagram\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCb1f0DmMUay",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_camera_images():\n",
    "    system = DepthCameraDemoSystem()\n",
    "\n",
    "    # Evaluate the camera output ports to get the images.\n",
    "    context = system.CreateDefaultContext()\n",
    "    system.Publish(context)\n",
    "    color_image = system.GetOutputPort(\"color_image\").Eval(context)\n",
    "    depth_image = system.GetOutputPort(\"depth_image\").Eval(context)\n",
    "\n",
    "    # Plot the two images.\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(color_image.data)\n",
    "    plt.title('Color image')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.squeeze(depth_image.data))\n",
    "    plt.title('Depth image')\n",
    "    #mpld3.display()\n",
    "    plt.show()\n",
    "\n",
    "plot_camera_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wya-_6_3MUa1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_diagram():\n",
    "    system = DepthCameraDemoSystem()\n",
    "    display(SVG(pydot.graph_from_dot_data(system.GetGraphvizString(max_depth=1))[0].create_svg()))\n",
    "\n",
    "draw_diagram()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFNDRsZ1MUa4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_manipulation_station_camera_images():\n",
    "    station = MakeManipulationStation(\n",
    "        filename=FindResource(\"models/clutter_mustard.dmd.yaml\"))\n",
    "    context = station.CreateDefaultContext()\n",
    "\n",
    "    index = 1\n",
    "    plt.figure(figsize=(6, 12))\n",
    "    for camera_num in range(6):\n",
    "        color_image = station.GetOutputPort(\n",
    "            f\"camera{camera_num}_rgb_image\").Eval(context)\n",
    "        depth_image = station.GetOutputPort(\n",
    "            f\"camera{camera_num}_depth_image\").Eval(context)\n",
    "\n",
    "        plt.subplot(6, 2, index)\n",
    "        plt.imshow(color_image.data)\n",
    "        index += 1\n",
    "        plt.title('Color image')\n",
    "        plt.subplot(6, 2, index)\n",
    "        plt.imshow(np.squeeze(depth_image.data))\n",
    "        index += 1\n",
    "        plt.title('Depth image')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_manipulation_station_camera_images()\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Robotic Manipulation - Geometric Pose Estimation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
