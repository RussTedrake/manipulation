{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EgiF12Hf1Dhs"
   },
   "source": [
    "This notebook provides examples to go along with the [textbook](http://manipulation.csail.mit.edu/pose.html).  I recommend having both windows open, side-by-side!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eeMrMI0-1Dhu"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import mpld3\n",
    "import numpy as np\n",
    "import pydot\n",
    "from IPython.display import HTML, SVG, display\n",
    "from pydrake.all import (\n",
    "    AbstractValue,\n",
    "    AddMultibodyPlantSceneGraph,\n",
    "    BaseField,\n",
    "    ConstantValueSource,\n",
    "    DepthImageToPointCloud,\n",
    "    DiagramBuilder,\n",
    "    MeshcatPointCloudVisualizer,\n",
    "    MeshcatVisualizer,\n",
    "    MeshcatVisualizerParams,\n",
    "    Parser,\n",
    "    PointCloud,\n",
    "    RigidTransform,\n",
    "    RollPitchYaw,\n",
    "    RotationMatrix,\n",
    "    StartMeshcat,\n",
    ")\n",
    "\n",
    "from manipulation import ConfigureParser, running_as_notebook\n",
    "from manipulation.scenarios import (\n",
    "    AddMultibodyTriad,\n",
    "    AddRgbdSensor,\n",
    "    MakeManipulationStation,\n",
    ")\n",
    "\n",
    "if running_as_notebook:\n",
    "    mpld3.enable_notebook()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the visualizer.\n",
    "meshcat = StartMeshcat()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7q0A14bAilIX"
   },
   "source": [
    "# Simulating an RGB-D camera\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ILYLouFTjv6e"
   },
   "outputs": [],
   "source": [
    "def DepthCameraDemoSystem():\n",
    "    builder = DiagramBuilder()\n",
    "\n",
    "    # Create the physics engine + scene graph.\n",
    "    plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.0)\n",
    "    # Add a single object into it.\n",
    "    X_Mustard = RigidTransform(\n",
    "        RollPitchYaw(-np.pi / 2.0, 0, -np.pi / 2.0), [0, 0, 0.09515]\n",
    "    )\n",
    "    parser = Parser(plant)\n",
    "    ConfigureParser(parser)\n",
    "    mustard = parser.AddModelsFromUrl(\n",
    "        \"package://drake/manipulation/models/ycb/sdf/006_mustard_bottle.sdf\"\n",
    "    )[0]\n",
    "    plant.WeldFrames(\n",
    "        plant.world_frame(),\n",
    "        plant.GetFrameByName(\"base_link_mustard\", mustard),\n",
    "        X_Mustard,\n",
    "    )\n",
    "\n",
    "    # Add a box for the camera in the environment.\n",
    "    X_Camera = RigidTransform(\n",
    "        RollPitchYaw(0, -0.2, 0.2)\n",
    "        .ToRotationMatrix()\n",
    "        .multiply(\n",
    "            RollPitchYaw(-np.pi / 2.0, 0, np.pi / 2.0).ToRotationMatrix()\n",
    "        ),\n",
    "        [0.5, 0.1, 0.2],\n",
    "    )\n",
    "    camera_instance = parser.AddModelsFromUrl(\n",
    "        \"package://manipulation/camera_box.sdf\"\n",
    "    )[0]\n",
    "    camera_frame = plant.GetFrameByName(\"base\", camera_instance)\n",
    "    plant.WeldFrames(plant.world_frame(), camera_frame, X_Camera)\n",
    "    AddMultibodyTriad(camera_frame, scene_graph, length=0.1, radius=0.005)\n",
    "    plant.Finalize()\n",
    "\n",
    "    params = MeshcatVisualizerParams()\n",
    "    #    params.delete_on_initialization_event = False\n",
    "    visualizer = MeshcatVisualizer.AddToBuilder(\n",
    "        builder, scene_graph, meshcat, params\n",
    "    )\n",
    "\n",
    "    camera = AddRgbdSensor(\n",
    "        builder,\n",
    "        scene_graph,\n",
    "        X_PC=RigidTransform(),\n",
    "        parent_frame_id=plant.GetBodyFrameIdOrThrow(\n",
    "            camera_frame.body().index()\n",
    "        ),\n",
    "    )\n",
    "    camera.set_name(\"rgbd_sensor\")\n",
    "\n",
    "    # Export the camera outputs\n",
    "    builder.ExportOutput(camera.color_image_output_port(), \"color_image\")\n",
    "    builder.ExportOutput(camera.depth_image_32F_output_port(), \"depth_image\")\n",
    "\n",
    "    # Add a system to convert the camera output into a point cloud\n",
    "    to_point_cloud = builder.AddSystem(\n",
    "        DepthImageToPointCloud(\n",
    "            camera_info=camera.depth_camera_info(),\n",
    "            fields=BaseField.kXYZs | BaseField.kRGBs,\n",
    "        )\n",
    "    )\n",
    "    builder.Connect(\n",
    "        camera.depth_image_32F_output_port(),\n",
    "        to_point_cloud.depth_image_input_port(),\n",
    "    )\n",
    "    builder.Connect(\n",
    "        camera.color_image_output_port(),\n",
    "        to_point_cloud.color_image_input_port(),\n",
    "    )\n",
    "\n",
    "    # Send the point cloud to meshcat for visualization, too.\n",
    "    point_cloud_visualizer = builder.AddSystem(\n",
    "        MeshcatPointCloudVisualizer(meshcat, \"cloud\")\n",
    "    )\n",
    "    builder.Connect(\n",
    "        to_point_cloud.point_cloud_output_port(),\n",
    "        point_cloud_visualizer.cloud_input_port(),\n",
    "    )\n",
    "    camera_pose = builder.AddSystem(\n",
    "        ConstantValueSource(AbstractValue.Make(X_Camera))\n",
    "    )\n",
    "    builder.Connect(\n",
    "        camera_pose.get_output_port(), point_cloud_visualizer.pose_input_port()\n",
    "    )\n",
    "\n",
    "    # Export the point cloud output.\n",
    "    builder.ExportOutput(\n",
    "        to_point_cloud.point_cloud_output_port(), \"point_cloud\"\n",
    "    )\n",
    "\n",
    "    diagram = builder.Build()\n",
    "    diagram.set_name(\"depth_camera_demo_system\")\n",
    "    return diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WCb1f0DmMUay",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_camera_images():\n",
    "    system = DepthCameraDemoSystem()\n",
    "\n",
    "    # Evaluate the camera output ports to get the images.\n",
    "    context = system.CreateDefaultContext()\n",
    "    system.ForcedPublish(context)\n",
    "    color_image = system.GetOutputPort(\"color_image\").Eval(context)\n",
    "    depth_image = system.GetOutputPort(\"depth_image\").Eval(context)\n",
    "\n",
    "    # Plot the two images.\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(color_image.data)\n",
    "    plt.title(\"Color image\")\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(np.squeeze(depth_image.data))\n",
    "    plt.title(\"Depth image\")\n",
    "    # mpld3.display()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_camera_images()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wya-_6_3MUa1",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def draw_diagram():\n",
    "    system = DepthCameraDemoSystem()\n",
    "    display(\n",
    "        SVG(\n",
    "            pydot.graph_from_dot_data(system.GetGraphvizString(max_depth=1))[\n",
    "                0\n",
    "            ].create_svg()\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "draw_diagram()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mFNDRsZ1MUa4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_manipulation_station_camera_images():\n",
    "    station = MakeManipulationStation(\n",
    "        filename=\"package://manipulation/clutter_mustard.dmd.yaml\"\n",
    "    )\n",
    "    context = station.CreateDefaultContext()\n",
    "\n",
    "    index = 1\n",
    "    plt.figure(figsize=(6, 12))\n",
    "    for camera_num in range(6):\n",
    "        color_image = station.GetOutputPort(\n",
    "            f\"camera{camera_num}_rgb_image\"\n",
    "        ).Eval(context)\n",
    "        depth_image = station.GetOutputPort(\n",
    "            f\"camera{camera_num}_depth_image\"\n",
    "        ).Eval(context)\n",
    "\n",
    "        plt.subplot(6, 2, index)\n",
    "        plt.imshow(color_image.data)\n",
    "        index += 1\n",
    "        plt.title(\"Color image\")\n",
    "        plt.subplot(6, 2, index)\n",
    "        plt.imshow(np.squeeze(depth_image.data))\n",
    "        index += 1\n",
    "        plt.title(\"Depth image\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_manipulation_station_camera_images()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Robotic Manipulation - Geometric Pose Estimation.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "metadata": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
