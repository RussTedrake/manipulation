{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VEYe67K6E6j0"
   },
   "source": [
    "## **Grasp Candidate Sampling**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VsbCH_XUJDCN"
   },
   "source": [
    "## Notebook Setup \n",
    "The following cell will install Drake, checkout the manipulation repository, and set up the path (only if necessary).\n",
    "- On Google's Colaboratory, this **will take approximately two minutes** on the first time it runs (to provision the machine), but should only need to reinstall once every 12 hours.  \n",
    "\n",
    "More details are available [here](http://manipulation.mit.edu/drake.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "v5OrhpSmxkGH"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os, sys\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "if 'google.colab' in sys.modules and importlib.util.find_spec('manipulation') is None:\n",
    "    urlretrieve(f\"http://manipulation.csail.mit.edu/scripts/setup/setup_manipulation_colab.py\",\n",
    "                \"setup_manipulation_colab.py\")\n",
    "    from setup_manipulation_colab import setup_manipulation\n",
    "    setup_manipulation(manipulation_sha='db19656799c11a58bc37dd20604ad38eafb09c62', drake_version='20201007', drake_build='nightly')\n",
    "\n",
    "from IPython import get_ipython\n",
    "running_as_notebook = get_ipython() and hasattr(get_ipython(), 'kernel')\n",
    "\n",
    "# Setup rendering (with xvfb), if necessary:\n",
    "import os\n",
    "if 'google.colab' in sys.modules and os.getenv(\"DISPLAY\") is None:\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(1400, 900))\n",
    "    display.start()\n",
    "\n",
    "# setup ngrok server\n",
    "server_args = []\n",
    "if 'google.colab' in sys.modules:\n",
    "  server_args = ['--ngrok_http_tunnel']\n",
    "\n",
    "from meshcat.servers.zmqserver import start_zmq_server_as_subprocess\n",
    "proc, zmq_url, web_url = start_zmq_server_as_subprocess(server_args=server_args)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pydrake.all import ( \n",
    "    AddMultibodyPlantSceneGraph, ConnectMeshcatVisualizer, \n",
    "    DiagramBuilder, RigidTransform, RotationMatrix, Parser, Simulator,\n",
    "    FindResourceOrThrow\n",
    ")\n",
    "\n",
    "import open3d as o3d\n",
    "import meshcat\n",
    "import meshcat.geometry as g\n",
    "import meshcat.transformations as tf\n",
    "\n",
    "from manipulation.meshcat_utils import draw_open3d_point_cloud\n",
    "from manipulation.utils import FindResource\n",
    "\n",
    "# Load mustard bottle pointcloud from online. \n",
    "urlretrieve(f\"http://hjrobotics.net/wp-content/uploads/2020/10/mustard_bottle.pcd\",\n",
    "            \"mustard_bottle.pcd\")\n",
    "pcd = o3d.io.read_point_cloud(\"mustard_bottle.pcd\")\n",
    "\n",
    "vis = meshcat.Visualizer(zmq_url=zmq_url)\n",
    "vis[\"/Background\"].set_property(\"visible\", False)\n",
    "draw_open3d_point_cloud(vis, pcd)\n",
    "\n",
    "def setup_grasp_diagram(draw_frames=True):\n",
    "  builder = DiagramBuilder()\n",
    "  plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.001)\n",
    "  parser = Parser(plant)\n",
    "  parser.package_map().Add(\"wsg_50_description\", os.path.dirname(FindResourceOrThrow(\"drake/manipulation/models/wsg_50_description/package.xml\")))\n",
    "  gripper = parser.AddModelFromFile(FindResource(\n",
    "      \"models/schunk_wsg_50_welded_fingers.sdf\"), \"gripper\")\n",
    "  plant.Finalize()  \n",
    "\n",
    "  frames_to_draw = {\"gripper\": {\"body\"}} if draw_frames else {}\n",
    "  meshcat_vis = ConnectMeshcatVisualizer(builder, scene_graph, zmq_url=zmq_url, delete_prefix_on_load=False, frames_to_draw=frames_to_draw)\n",
    "  diagram = builder.Build()\n",
    "  context = diagram.CreateDefaultContext()\n",
    "\n",
    "  return plant, scene_graph, diagram, context, meshcat_vis\n",
    "\n",
    "# Now we'll use this as a global variable. \n",
    "drake_params = setup_grasp_diagram()\n",
    "\n",
    "def draw_grasp_candidate(X_G, prefix='gripper', refresh=False):\n",
    "  plant, scene_graph, diagram, context, meshcat_vis = drake_params\n",
    "  if (refresh):\n",
    "    meshcat_vis.vis.delete()\n",
    "\n",
    "  plant_context = plant.GetMyContextFromRoot(context)\n",
    "  plant.SetFreeBodyPose(plant_context, \n",
    "                        plant.GetBodyByName(\"body\"), X_G)\n",
    "  meshcat_vis.load()\n",
    "  diagram.Publish(context)\n",
    "\n",
    "  X_G = plant.GetFreeBodyPose(plant_context,\n",
    "                        plant.GetBodyByName(\"body\"))\n",
    "  \n",
    "def draw_grasp_candidates(X_G, prefix='gripper', draw_frames=True):\n",
    "  builder = DiagramBuilder()\n",
    "  plant, scene_graph = AddMultibodyPlantSceneGraph(builder, time_step=0.001)\n",
    "  parser = Parser(plant)\n",
    "  parser.package_map().Add(\"wsg_50_description\", os.path.dirname(FindResourceOrThrow(\"drake/manipulation/models/wsg_50_description/package.xml\")))\n",
    "  gripper = parser.AddModelFromFile(FindResource(\n",
    "      \"models/schunk_wsg_50_welded_fingers.sdf\"), \"gripper\")\n",
    "  plant.WeldFrames(plant.world_frame(), plant.GetFrameByName(\"body\"), X_G)\n",
    "  plant.Finalize()\n",
    "  \n",
    "  frames_to_draw = {\"gripper\": {\"body\"}} if draw_frames else {}\n",
    "  meshcat = ConnectMeshcatVisualizer(builder, scene_graph, zmq_url=zmq_url, prefix=prefix, delete_prefix_on_load=False, frames_to_draw=frames_to_draw)\n",
    "  diagram = builder.Build()\n",
    "  context = diagram.CreateDefaultContext()\n",
    "\n",
    "  meshcat.load()\n",
    "  diagram.Publish(context)\n",
    "\n",
    "def draw_frame_meshcat(vis, frame_name, X_AB, scale):\n",
    "  vis[frame_name].set_object(meshcat.geometry.triad(scale=scale))\n",
    "  vis[frame_name].set_transform(X_AB.GetAsMatrix4())\n",
    "\n",
    "def compute_sdf(pcd, X_G, visualize=False):\n",
    "  plant, scene_graph, diagram, context, meshcat_vis = drake_params\n",
    "  plant_context = plant.GetMyContextFromRoot(context)\n",
    "  scene_graph_context = scene_graph.GetMyContextFromRoot(context)\n",
    "  plant.SetFreeBodyPose(plant_context, \n",
    "                        plant.GetBodyByName(\"body\"), X_G)\n",
    "  \n",
    "  if (visualize):\n",
    "    meshcat_vis.load()\n",
    "    diagram.Publish(context)\n",
    "\n",
    "  query_object = scene_graph.get_query_output_port().Eval(scene_graph_context)\n",
    "\n",
    "  pcd_sdf = np.inf \n",
    "  for pt in pcd.points:\n",
    "    distances = query_object.ComputeSignedDistanceToPoint(pt)\n",
    "    for body_index in range(len(distances)):\n",
    "      distance = distances[body_index].distance\n",
    "      if distance < pcd_sdf:\n",
    "        pcd_sdf = distance\n",
    "\n",
    "  return pcd_sdf \n",
    "\n",
    "def check_collision(pcd, X_G, visualize=False):\n",
    "  sdf = compute_sdf(pcd, X_G, visualize)\n",
    "  return (sdf > 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZUg7IbDmIyeo"
   },
   "source": [
    "## Grasp Candidate based on Local Curvature \n",
    "\n",
    "This is an implementation-heavy assignment, where we will implement a variation of the grasp candidate sampling algorithm on [this paper](https://arxiv.org/pdf/1706.09911.pdf). It is from 2017, so we are really doing some cutting-edge techniques! Parts of the [library](https://github.com/atenpas/gpg) based on the paper, which the authors have named \"Grasp Pose Generator\" (GPG), is used in real grasp selection systems including the one being run at Toyota Research Institute. \n",
    "\n",
    "As opposed to sampling candidate grasp poses using the \"antipodal heuristic\", this sampling algorithm uses a heuristic based on the local curvature. This heursitic can work quite well especially for smoother / symmetrical objects which has relatively consistent curvature characteristics. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1PAeSQRiHRNi"
   },
   "source": [
    "## Computing the Darboux Frame\n",
    "\n",
    "First, let's work on formalizing our notion of a \"local curvature\" by bringing up the [**Darboux Frame**](https://en.wikipedia.org/wiki/Darboux_frame) from differential geometry. It has a fancy French name (after its creator), but the concept is quite simple.\n",
    "\n",
    "Given a point $p\\in\\mathbb{R}^3$ on a differentiable surface $\\mathcal{S}\\subset\\mathbb{R}^3$, we've seen that we can compute the normal vector at point $p$. Let's denote this vector as $n(p)$. \n",
    "\n",
    "The Darboux frame first aligns the $y$-axis with the inward normal vector, and aligns the $x$ and $z$ axis with principal axii of the tangent surface given the curvature. We will define the axis as \n",
    "- x-axis: aligned with the major axis of curvature at point $p$.\n",
    "- y-axis: aligned with the inward normal vector at point $p$.\n",
    "- z-axis: aligned with the minor axis of curvature at point $p$. \n",
    "\n",
    "Where major axis of curvature has a smaller radius of curvature compared to the minor axis. The below figure might clear things up. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/RussTedrake/manipulation/master/figures/exercises/darboux_frame.png\" width=\"400\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J5WdmM8hQkQ7"
   },
   "source": [
    "Below, your job is to compute the RigidTransform from the world to the Darboux frame of a specific point on the pointcloud. \n",
    "\n",
    "Here is a simple outline of the algorithm that we've seeen in class:\n",
    "1. Compute the set of points $\\mathcal{S}$ around the given point using [`kdtree.search_hybrid_vector3d`](http://www.open3d.org/docs/release/python_api/open3d.geometry.KDTreeFlann.html?highlight=search_hybrid_vector#open3d.geometry.KDTreeFlann.search_hybrid_vector_3d), with `ball_radius` as the distance parameter.  \n",
    "2. Compute the $3\\times3$ matrix with sum of outer-products of the normal vectors. \n",
    "$$\\mathbf{N}=\\sum_{p\\in\\mathcal{S}} n(p)n^T(p)$$\n",
    "3. Run eigen decomposition and get the eigenvectors using `np.linalg.eig`. Denote the eigen vectors as $[v_1, v_2, v_3]$, in order of decreasing corresponding eigenvalues. Convince yourself that:\n",
    "- $v_1$ is the normal vector,\n",
    "- $v_2$ is the major tangent vector, \n",
    "- $v_3$ is the minor tangent vector. \n",
    "4. If $v_1$ is heading outwards (same direction as $n(p)$), negate $v_1$\n",
    "5. Using $v_1,v_2,v_3$, construct the Rotation matrix by horizontally stacking the vertical vectors: $\\mathbf{R} = [v_2 | v_1 | v_3]$\n",
    "6. If the rotation is improper, negate $v_2$\n",
    "5. Return a `RigidTransform` that has the rotation set as defined in the figure above, and translation defined at the desired point.  \n",
    "\n",
    "NOTE: Convince yourself of the following: if you knew the orthonormal basis vectors of a frame ${}^W[i,j,k]$, then the Rotation matrix of of that frame with respect to the world ${}^W\\mathbf{R}^F$ can be computed by horizontally stacking the vertical vectors ($[i|j|k]$). Why would this be? (This doesn't necessarily mean the eigenvector matrix is always a rotation matrix due to improper rotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WRuwFwcuTQtw"
   },
   "outputs": [],
   "source": [
    "def compute_darboux_frame(index, pcd, kdtree, ball_radius=0.002, max_nn=50):\n",
    "  \"\"\"\n",
    "  Given a index of the pointcloud, return a RigidTransform from world to the \n",
    "  Darboux frame at that point.\n",
    "  Args: \n",
    "  - index (int): index of the pointcloud. \n",
    "  - pcd (o3d.pointcloud object): open3d pointcloud of the object.\n",
    "  - kdtree (o3d.geometry.KDTreeFlann object): kd tree to use for nn search. \n",
    "  - ball_radius (float): ball_radius used for nearest-neighbors search \n",
    "  - max_nn (int): maximum number of points considered in nearest-neighbors search. \n",
    "  \"\"\"\n",
    "  points = np.asarray(pcd.points) # Nx3 np array of points\n",
    "  normals = np.asarray(pcd.normals) # Nx3 np array of normals\n",
    "\n",
    "  # Fill in your code here. \n",
    "  X_WF = RigidTransform() # modify here.\n",
    " \n",
    "  return X_WF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3Nmr31JUZPB"
   },
   "source": [
    "You can check your work by running the cell below and looking at the frame visualization in Meshcat. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TcNpDwGiZw1n"
   },
   "outputs": [],
   "source": [
    "# 151, 11121 are pretty good verifiers of the implementation.\n",
    "index = 151\n",
    "vis = meshcat.Visualizer(zmq_url=zmq_url)\n",
    "vis.delete() \n",
    "\n",
    "# Build KD tree.\n",
    "kdtree = o3d.geometry.KDTreeFlann(pcd)\n",
    "X_WP = compute_darboux_frame(index, pcd, kdtree)\n",
    "draw_open3d_point_cloud(vis, pcd)\n",
    "draw_frame_meshcat(vis, \"frame\", X_WP, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HrdDJyHzU4W_"
   },
   "source": [
    "## Collision Line Search \n",
    "\n",
    "Now we wish to align our gripper frame with the Darboux frame that we found, but naively doing it will result in collision / being too far from the object.\n",
    "\n",
    "An important heuristic that is used in the GPG work is that grasps are more stable when contact area is maximized. For that, we would need the gripper to be as inwards as possible towards the object but avoid collisions.\n",
    "\n",
    "To implement this, we will use a line search along a grid along the y-axis, and find the **maximum** value of $y$ (remember that our $y$ is towards the inwards normal) that results in no-collision. \n",
    "\n",
    "We've given you the grid you should search over, and the function `distance=compute_sdf(pcd, X_WG)` that will return the signed distance function between the set of pointclouds, and the gripper, given the transform `X_WG`. You are required to use this to detect the presence of collisions. \n",
    "\n",
    "Finally, if there is no value of $y$ that results in no collisions, you should return `np.nan` for the signed distance, and `None` for the rigid transform. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tUgWtIoDW-x2"
   },
   "outputs": [],
   "source": [
    "# Compute static rotation between the frame and the gripper. \n",
    "def find_minimum_distance(pcd, X_WG):\n",
    "  \"\"\"\n",
    "  By doing line search, compute the maximum allowable distance along the y axis before penetration.\n",
    "  Return the maximum distance, as well as the new transform.\n",
    "  Args:\n",
    "    - pcd (open3d.geometry.Pointcloud object): pointcloud to search over.\n",
    "    - X_WG (Drake RigidTransform object): RigidTransform. You can expect this to be the return from compute_darboux_frame.  \n",
    "  Return:\n",
    "    - Tuple (signed_distance, X_WGnew) where\n",
    "    - signed_distance (float): signed distance between gripper and object pointcloud at X_WGnew. \n",
    "    - X_WGnew: New rigid transform that moves X_WG along the y axis while maximizing the y-translation subject to no collision. \n",
    "    If there is no value of y that results in no collisions, return (np.nan, None). \n",
    "  \"\"\"\n",
    "  y_grid = np.linspace(-0.05, 0.05, 10) # do not modify \n",
    "\n",
    "  # modify here. \n",
    "  signed_distance = 0.0 # modify here \n",
    "  X_WGnew = RigidTransform() # modify here\n",
    "\n",
    "  return signed_distance, X_WGnew"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s3E771RFXO7N"
   },
   "source": [
    "You can check your work below by running the cell below. If the visualization results in a collision, or the gripper is excessively far from the object, your implementation is probably wrong. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NvPNcEzpWqzt"
   },
   "outputs": [],
   "source": [
    "vis = meshcat.Visualizer(zmq_url=zmq_url)\n",
    "vis.delete()\n",
    "draw_open3d_point_cloud(vis, pcd)\n",
    "draw_frame_meshcat(vis, \"frame\", X_WP, 0.1)\n",
    "shortest_distance, X_WGnew = find_minimum_distance(pcd, X_WP)\n",
    "draw_grasp_candidate(X_WGnew, refresh=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ivgvyXpVXiXn"
   },
   "source": [
    "## Nonempty Grasp \n",
    "\n",
    "Let's add one more heuristic: when we close the gripper, we don't want what is in between the two fingers to be an empty region. That would make our robot look not very smart! \n",
    "\n",
    "There is a simple way to check this: let's define a volumetric region swept by the gripper's closing trajectory, and call it $\\mathcal{B}(^{W}X^{G})$. We will also call the gripper body (when fully open) as the set $\\mathcal{C}(^{W}X^G)$. If there are no object pointclouds within the set $\\mathcal{B}(^{W}X^{G})$, we can simply discard it. \n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/RussTedrake/manipulation/master/figures/exercises/closing_plane.png\" width=\"800\">\n",
    "\n",
    "You're probably thinking - how do I do a rigid transform on a set? Generally it's doable if the transform is affine, the set is polytopic, etc., but there is an easier trick - we just transform all the pointclouds to the gripper frame $G$! \n",
    "\n",
    "Your algorithm below will follow these step:\n",
    "  1. Transform the pointcloud points `pcd` from world frame to gripper frame.\n",
    "  2. For each point, check if it is within the bounding box we have provided.\n",
    "  3. If there is a point inside the set, return True. If not, return false. \n",
    "\n",
    "HINT: Our implementation uses no for-loops for this one. You can look into `np.all` for an extra boost of speed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EuDXAeQZbhgR"
   },
   "outputs": [],
   "source": [
    "def check_nonempty(pcd, X_WG, visualize=False):\n",
    "  \"\"\"\n",
    "  Check if the \"closing region\" of the gripper is nonempty by transforming the pointclouds to gripper coordinates. \n",
    "  Args:\n",
    "    - pcd (open3d.geometry.Pointcloud): open3d pointcloud class \n",
    "    - X_WG (Drake RigidTransform): transform of the gripper.\n",
    "  Return:\n",
    "    - is_nonempty (boolean): boolean set to True if there is a point within the cropped region. \n",
    "  \"\"\"\n",
    "  pcd_W_np = np.array(pcd.points) \n",
    "\n",
    "  # Bounding box of the closing region written in the coordinate frame of the gripper body. \n",
    "  # Do not modify \n",
    "  crop_min = [-0.054, 0.036, -0.01]\n",
    "  crop_max = [0.054, 0.117, 0.01]\n",
    "\n",
    "  ############### modify from here. \n",
    "\n",
    "  pcd_G_np = pcd_W_np # modify to get pointcloud seen from Gripper frame. Don't change the variable name. \n",
    "  is_nonempty = False\n",
    "\n",
    "  ############### Do not modify beyond. \n",
    "\n",
    "  if (visualize):\n",
    "    vis.delete()\n",
    "    pcd_G = o3d.geometry.PointCloud() \n",
    "    pcd_G.points = o3d.utility.Vector3dVector(pcd_G_np)\n",
    "    pcd_G.colors = pcd.colors\n",
    "\n",
    "    draw_grasp_candidate(RigidTransform())\n",
    "    draw_open3d_point_cloud(vis, pcd_G)\n",
    "    \n",
    "    box_length = np.array(crop_max) - np.array(crop_min)\n",
    "    box_center = (np.array(crop_max) + np.array(crop_min)) / 2. \n",
    "    box = g.Box(box_length)\n",
    "    vis[\"closing_region\"].set_object(box, g.MeshLambertMaterial(color=0xff0000, opacity=0.3))\n",
    "    vis[\"closing_region\"].set_transform(tf.translation_matrix(box_center))\n",
    "\n",
    "  return is_nonempty "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_SIw8uGhb2P-"
   },
   "source": [
    "You can check the correctness of your implementation by running the below cell, where we have visualized the pointclouds and $\\mathcal{B}({}^W X^G)$ from the gripper frame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BBg0NCWd2qI8"
   },
   "outputs": [],
   "source": [
    "# Lower and upper bounds of the closing region in gripper coordinates. Do not modify. \n",
    "vis = meshcat.Visualizer(zmq_url=zmq_url)\n",
    "check_nonempty(pcd, X_WGnew, visualize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dwGE2JDnXmY5"
   },
   "source": [
    "## Grasp Sampling Algorithm\n",
    "\n",
    "That was a lot of subcomponents, but we're finally onto the grand assembly. You will now generate `candidate_num` candidate grasps using everything we have written so far. The sampling algorithm goes as follows:\n",
    "\n",
    "1. Select a random point $p$ from the pointcloud (use `np.random.randint()`)\n",
    "2. Compute the Darboux frame ${}^WX^F(p)$ of the point $p$ using `compute_darboux_frame`. \n",
    "3. Randomly sample an $x$ direction translation $x\\in[x_{min},x_{max}]$, and a $z$ direction rotation $\\phi\\in[\\phi_{min},\\phi_{max}]$. Compute a grasp frame $T$ that has the relative transformation `X_FT=(RotateZ(phi),TranslateX(x))`. Convince yourself this makes the point $p$ stay in the \"closing plane\" (drawn in red) defined in the figure above. (NOTE: For ease of grading, make sure you compute the $x$ direction first with `np.random.rand()`, then compute the $\\phi$ direction with another call to `np.random.rand()`, not the other way around.) \n",
    "4. From the grasp frame $T$, translate along the $y$ axis such that the gripper is closest to the object without collision. Use `find_minimum_distance`, and call this frame $G$. Remember that `find_minimum_distance` can return `np.nan`. Skip the loop if this happens. \n",
    "5. If $G$ results in no collisions (see `check_collision`) and results in non-empty grasp (use `check_nonempty`), append it to the candidate list. If not, continue the loop until we have desired number of candidates. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LvKVHqv8fnq1"
   },
   "outputs": [],
   "source": [
    "def compute_candidate_grasps(pcd, candidate_num = 10, random_seed=5):\n",
    "  \"\"\"\n",
    "  Compute candidate grasps. \n",
    "  Args:\n",
    "    - pcd (open3d.geometry.Pointcloud): pointcloud of the object\n",
    "    - candidate_num (int) : number of desired candidates. \n",
    "    - random_seed (int) : seed for rng, used for grading. \n",
    "  Return:\n",
    "    - candidate_lst (list of drake RigidTransforms) : candidate list of grasps. \n",
    "  \"\"\"\n",
    "\n",
    "  # Do not modify.\n",
    "  x_min = -0.03\n",
    "  x_max = 0.03\n",
    "  phi_min = -np.pi/3\n",
    "  phi_max = np.pi/3\n",
    "  np.random.seed(random_seed)\n",
    "\n",
    "  # Build KD tree for the pointcloud. \n",
    "  kdtree = o3d.geometry.KDTreeFlann(pcd)\n",
    "  ball_radius = 0.002\n",
    "\n",
    "  candidate_count = 0 \n",
    "  candidate_lst = [] # list of candidates, given by RigidTransforms. \n",
    "\n",
    "  # Modify from here. \n",
    "\n",
    "  \n",
    "  return candidate_lst"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dypaCKcOf9cn"
   },
   "source": [
    "You can check your implementation by running the cell below. Note that although we've only sampled 20 candidates, a lot of them look promising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ItS9GtKaZ39w"
   },
   "outputs": [],
   "source": [
    "# Takes approximately 40 seconds.\n",
    "if (running_as_notebook):\n",
    "  grasp_candidates = compute_candidate_grasps(pcd, candidate_num=3, random_seed=5)\n",
    "\n",
    "  vis.delete()\n",
    "  draw_open3d_point_cloud(vis, pcd)\n",
    "  for i in range(len(grasp_candidates)):\n",
    "    draw_grasp_candidates(grasp_candidates[i], prefix=\"gripper\" + str(i), draw_frames=False)\n",
    "else:\n",
    "  grasp_candidates = compute_candidate_grasps(pcd, candidate_num=1, random_seed=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7jcCyk-q2U3L"
   },
   "source": [
    "## Note on Running Time\n",
    "\n",
    "You might be disappointed in how slowly this runs, but the same algorithm written in C++ with optimized libraries can run much faster. (I would expect around a 20 times speedup). \n",
    "\n",
    "But more fundamentally, it's important to note how trivially parallelizable the candidate sampling process is. With a parallelized and optimized implementation, hundres can be sampled in real time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MwE8yNg58VQN"
   },
   "source": [
    "## How will this notebook be Graded?##\n",
    "\n",
    "If you are enrolled in the class, this notebook will be graded using [Gradescope](www.gradescope.com). You should have gotten the enrollement code on our announcement in Piazza. \n",
    "\n",
    "For submission of this assignment, you must do two things. \n",
    "- Download and submit the notebook `grasp_candidate.ipynb` to Gradescope's notebook submission section, along with your notebook for the other problems.\n",
    "\n",
    "We will evaluate the local functions in the notebook to see if the function behaves as we have expected. For this exercise, the rubric is as follows:\n",
    "- [4 pts] `compute_darboux_frame` must be implemented correctly.\n",
    "- [4 pts] `find_minimum_distance` must be implemented correctly.\n",
    "- [2 pts] `check_nonempty` must be implemented correctly.\n",
    "- [4 pts] `compute_candidate_grasps` must be implemented correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xj5nAh4g8VQO"
   },
   "outputs": [],
   "source": [
    "from manipulation.exercises.clutter.test_grasp_candidate import TestGraspCandidate\n",
    "from manipulation.exercises.grader import Grader \n",
    "\n",
    "Grader.grade_output([TestGraspCandidate], [locals()], 'results.json')\n",
    "Grader.print_test_results('results.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "grasp_candidate.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}