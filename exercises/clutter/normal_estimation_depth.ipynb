{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CagYlhclDR4"
   },
   "source": [
    "# Normal Estimation from Depth Image\n",
    "\n",
    "## Notebook Setup \n",
    "The following cell will install Drake, checkout the manipulation repository, and set up the path (only if necessary).\n",
    "- On Google's Colaboratory, this **will take approximately two minutes** on the first time it runs (to provision the machine), but should only need to reinstall once every 12 hours.  \n",
    "\n",
    "More details are available [here](http://manipulation.mit.edu/drake.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_GMCWQ1RjBoB"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os, sys\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "if 'google.colab' in sys.modules and importlib.util.find_spec('manipulation') is None:\n",
    "    urlretrieve(f\"http://manipulation.csail.mit.edu/scripts/setup/setup_manipulation_colab.py\",\n",
    "                \"setup_manipulation_colab.py\")\n",
    "    from setup_manipulation_colab import setup_manipulation\n",
    "    setup_manipulation(manipulation_sha='2005dfea3fc8a2d675e8707b94958a82f1aaf5bb', drake_version='20201007', drake_build='nightly')\n",
    "\n",
    "from IPython import get_ipython\n",
    "running_as_notebook = get_ipython() and hasattr(get_ipython(), 'kernel')\n",
    "\n",
    "# Setup rendering (with xvfb), if necessary:\n",
    "import os\n",
    "if 'google.colab' in sys.modules and os.getenv(\"DISPLAY\") is None:\n",
    "    from pyvirtualdisplay import Display\n",
    "    display = Display(visible=0, size=(1400, 900))\n",
    "    display.start()\n",
    "\n",
    "# setup ngrok server\n",
    "server_args = []\n",
    "if 'google.colab' in sys.modules:\n",
    "  server_args = ['--ngrok_http_tunnel']\n",
    "\n",
    "from meshcat.servers.zmqserver import start_zmq_server_as_subprocess\n",
    "proc, zmq_url, web_url = start_zmq_server_as_subprocess(server_args=server_args)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from pydrake.all import ( \n",
    "    AddMultibodyPlantSceneGraph, ConnectMeshcatVisualizer, \n",
    "    DiagramBuilder, RigidTransform, RotationMatrix, Parser, Simulator,\n",
    "    FindResourceOrThrow,Quaternion, AddTriad\n",
    ")\n",
    "\n",
    "import open3d as o3d\n",
    "import meshcat\n",
    "import meshcat.geometry as g\n",
    "import meshcat.transformations as tf\n",
    "\n",
    "from manipulation.meshcat_utils import draw_open3d_point_cloud, draw_points\n",
    "from manipulation.mustard_depth_camera_example import MustardExampleSystem\n",
    "from manipulation.utils import FindResource\n",
    "from manipulation.open3d_utils import create_open3d_point_cloud\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Rectangle\n",
    "from copy import deepcopy\n",
    "import pydot\n",
    "from ipywidgets import Dropdown, Layout\n",
    "from IPython.display import display, HTML, SVG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UxATaRk3jBoH"
   },
   "source": [
    "# Problem Description\n",
    "In the lecture, we learned about estimating the point cloud normal vectors and surface curvations. For this exercise, you will investigate a slightly different approach. In particular, you will exploit the structure already presented in a depth image to avoid computing nearest neighbors. \n",
    "\n",
    "**These are the main steps of the exercise:**\n",
    "1. Implement the `estimate_normal_by_nearest_pixels` method.\n",
    "2. Come up with an example that breaks the `estimate_normal_by_nearest_pixels` method.\n",
    "\n",
    "Run the cell below to set up the simulation environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "STaJPvHmjBoH"
   },
   "outputs": [],
   "source": [
    "class NormalEstimation:\n",
    "    def __init__(self):\n",
    "        diagram = MustardExampleSystem()\n",
    "        context = diagram.CreateDefaultContext()\n",
    "        \n",
    "        # setup\n",
    "        self.meshcat_vis = meshcat.Visualizer(zmq_url=zmq_url)\n",
    "        self.meshcat_vis[\"/Background\"].set_property(\"visible\", False)\n",
    "        \n",
    "        # getting data\n",
    "        self.point_cloud = diagram.GetOutputPort(\"camera0_point_cloud\").Eval(context)\n",
    "        self.rgb_im = diagram.GetOutputPort('camera0_rgb_image').Eval(context).data\n",
    "        self.depth_im_read = diagram.GetOutputPort('camera0_depth_image').Eval(context).data.squeeze()\n",
    "        self.depth_im = deepcopy(self.depth_im_read)\n",
    "        self.depth_im[self.depth_im == np.inf] = 10.0\n",
    "        label_im = diagram.GetOutputPort('camera0_label_image').Eval(context).data.squeeze()\n",
    "        pcd = create_open3d_point_cloud(self.point_cloud)\n",
    "        draw_open3d_point_cloud(self.meshcat_vis[\"self.point_cloud\"], pcd)\n",
    "        self.mask = label_im == 1\n",
    "        self.kdtree = o3d.geometry.KDTreeFlann(pcd)\n",
    "        self.pts = np.asarray(pcd.points)\n",
    "        \n",
    "        # camera specs\n",
    "        cam0 = diagram.GetSubsystemByName('camera0')\n",
    "        cam0_context = cam0.GetMyMutableContextFromRoot(context)\n",
    "        cam0_pose = cam0.GetOutputPort('X_WB').Eval(cam0_context)\n",
    "        self.cam_info = cam0.depth_camera_info()\n",
    "        self.X_WC = RigidTransform(quaternion=Quaternion(cam0_pose[3:]), p=cam0_pose[0:3])\n",
    "        \n",
    "    def project_depth_to_pC(self, depth_pixel, uv=None):\n",
    "        \"\"\"\n",
    "        project depth pixels to points in camera frame\n",
    "        using pinhole camera model\n",
    "        Input:\n",
    "            depth_pixels: numpy array of (nx3) or (3,)\n",
    "        Output:\n",
    "            pC: 3D point in camera frame, numpy array of (nx3)\n",
    "        \"\"\"\n",
    "        # switch u,v due to python convention\n",
    "        v = depth_pixel[:,0]\n",
    "        u = depth_pixel[:,1]\n",
    "        Z = depth_pixel[:,2]\n",
    "        # read camera intrinsics\n",
    "        cx = self.cam_info.center_x()\n",
    "        cy = self.cam_info.center_y()\n",
    "        fx = self.cam_info.focal_x()\n",
    "        fy = self.cam_info.focal_y()\n",
    "        X = (u-cx) * Z/fx\n",
    "        Y = (v-cy) * Z/fy\n",
    "        pC = np.c_[X,Y,Z]\n",
    "        return pC\n",
    "\n",
    "    def plot_scanning_window(self, u_range, v_range):\n",
    "        \"\"\"\n",
    "        visualize the scanning window\n",
    "        u_range: (u_start, u_end)\n",
    "        v_range: (v_start, v_end)\n",
    "        u, v are the 1st and 2nd axis of the image array\n",
    "        \"\"\"\n",
    "        # switch u, v range to get x, y\n",
    "        x0, x1 = v_range\n",
    "        y0, y1 = u_range\n",
    "        fig,  ax = plt.subplots()\n",
    "        ax.imshow(self.depth_im)\n",
    "        ax.add_patch( Rectangle((x0, y0), \n",
    "                                x1-x0, y1-y0,\n",
    "                                alpha=0.5,\n",
    "                                fc ='r') )\n",
    "    def vis_normals(self, normals):\n",
    "        \"\"\"\n",
    "        \"\"\"\n",
    "        for i in range(len(normals)):\n",
    "            name = 'normal_vec_{}'.format(i)\n",
    "            AddTriad(vis=self.meshcat_vis, name=name, prefix='', length=0.01, radius=0.001)\n",
    "            self.meshcat_vis[''][name].set_transform(normals[i].GetAsMatrix4())\n",
    "    \n",
    "def bbox(img):\n",
    "    a = np.where(img != 0)\n",
    "    bbox = ([np.min(a[0]), np.max(a[0])], [np.min(a[1]), np.max(a[1])])\n",
    "    return bbox\n",
    "        \n",
    "env = NormalEstimation()\n",
    "mask = env.mask\n",
    "depth_im = env.depth_im"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SevGI1izjBoN"
   },
   "source": [
    "The object of interest is the mustard bottle. Our goal in this exercise is to compute the estimate of point cloud normals of the mustard bottle from a depth image. The depth image is visualized below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TyACO5ThjBoO"
   },
   "outputs": [],
   "source": [
    "if (running_as_notebook):\n",
    "    plt.imshow(depth_im)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDpgse_ojBoS"
   },
   "source": [
    "The core idea of the approach is to exploit the fact that a depth image already includes spatial information among pixels. For example, for a selected pixel, the pixels that surround it are likely to be its nearest neighbors. Therefore, instead of computing nearest neighbors, we can instead use the nearest pixels in place of nearest neighbors. \n",
    "\n",
    "The cell below provides a sequence of screenshots of the method, where a square/rectangular window moves across the depth image. All pixels in the sliding window is used to compute the normal vector of the center point of the window. In your implementation below, you will use a smaller window and a smaller step size to get better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WD7U95EDjBoT"
   },
   "outputs": [],
   "source": [
    "uv_step = 40\n",
    "u_bound, v_bound = bbox(mask)\n",
    "for u in range(u_bound[0], u_bound[1], uv_step):\n",
    "    for v in range(v_bound[0], v_bound[1], uv_step):\n",
    "        center = [u,v]\n",
    "        u_length = 30\n",
    "        v_length = 30\n",
    "        if (running_as_notebook):\n",
    "            env.plot_scanning_window([center[0] - u_length, center[0] + u_length+1],\n",
    "                                    [center[1] - v_length, center[1] + v_length+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o-8vPWxdjBoX"
   },
   "source": [
    "## Mapping Depth Image to Point Cloud\n",
    "\n",
    "Note that pixel indices of a depth image is not a valid position measurement in the 3D world. Fortunately, there is a simple mapping from pixel locations to poses in the 3D world, and it is called the [pinhole camera model](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html). We have helped you map all pixels of the depth image to points in the camera frame in the cell below. In case you need to gain direct access to this mapping, please refer to the `project_depth_to_pC` method in the `NormalEstimation` class.\n",
    "\n",
    "The diagram below is found from [OpenCV documentation](https://docs.opencv.org/3.4/d9/d0c/group__calib3d.html). Note that the $u$ and $v$ directions are reversed in Python due to the difference in convention."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OaXlVRcskbDf"
   },
   "source": [
    "![](https://docs.opencv.org/3.4/pinhole_camera_model.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JHn2SKHDjBoY"
   },
   "outputs": [],
   "source": [
    "u_range = np.arange(depth_im.shape[0])\n",
    "v_range = np.arange(depth_im.shape[1])\n",
    "depth_v, depth_u = np.meshgrid(v_range, u_range)\n",
    "depth_pnts = np.dstack([depth_u, depth_v, depth_im])\n",
    "depth_pnts = depth_pnts.reshape([depth_pnts.shape[0]*depth_pnts.shape[1], 3])\n",
    "# point poses in camera frame\n",
    "pC =env.project_depth_to_pC(depth_pnts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "StDSt_MtjBoc"
   },
   "source": [
    "## Computing Surface Normals by Nearest Pixels\n",
    "Now you should be able to complete the implementation in the cell below. Note that locations of sliding windows are provided to you for the ease of grading. the pose of the depth camera is `X_WC`, **it is a different depth camera from the one shown in the meshcat visualizer**. \n",
    "\n",
    "**Complete the implementation of the `estimate_normal_by_nearest_pixels` below, make sure the +z axis of the normal frame points outward, toward the depth camera (different from the one shown in the meshcat visualizer)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "arTPxyRMjBod"
   },
   "outputs": [],
   "source": [
    "X_WC = env.X_WC\n",
    "def estimate_normal_by_nearest_pixels(X_WC, pC, uv_step=10):\n",
    "    \"\"\"\n",
    "    compute the surface normals from the nearest pixels (by a sliding window)\n",
    "    Input:\n",
    "        X_WC: RigidTransform of the camera in world frame\n",
    "        pC: 3D points computed from the depth image in the camera frame\n",
    "        uv_step: recommended step size for the sliding window (see codes below)\n",
    "    Output:\n",
    "        normals: a list of RigidTransforms of the normal frames in world frame.\n",
    "                 The +z axis of the normal frame is the normal vector, it should\n",
    "                 points outward (towards the camera)\n",
    "    \"\"\"\n",
    "    normals = []\n",
    "    u_bound, v_bound = bbox(mask)\n",
    "    for u in range(u_bound[0], u_bound[1], uv_step):\n",
    "        for v in range(v_bound[0], v_bound[1], uv_step):\n",
    "            # center of the window at depth_im[u,v]\n",
    "            center = [u,v]\n",
    "            u_length = 3\n",
    "            v_length = 3\n",
    "            # side of the window\n",
    "            u_range = np.arange(center[0] - u_length, center[0] + u_length+1)\n",
    "            v_range = np.arange(center[1] - v_length, center[1] + v_length+1)\n",
    "            ###################\n",
    "            # fill your code here\n",
    "            ###################\n",
    "    return normals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PD117pt0jBol"
   },
   "outputs": [],
   "source": [
    "normals = estimate_normal_by_nearest_pixels(X_WC, pC)\n",
    "env.vis_normals(normals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SfBjeNwmjBop"
   },
   "source": [
    "## Normal Vector Estimation with Noisy Depth\n",
    "\n",
    "The depth image tested in the first part of this exercise is a perfect depth image with no noise and missing values. Now imagine what will happen when noises and outliers are presented in the same depth image. \n",
    "\n",
    "**Illustrate a counter-example illustrating a case where the scanning window method cannot produce a good normal estimate.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w-z5MD-PjBoq"
   },
   "source": [
    "## How will this notebook be Graded?##\n",
    "\n",
    "If you are enrolled in the class, this notebook will be graded using [Gradescope](www.gradescope.com). You should have gotten the enrollement code on our announcement in Piazza. \n",
    "\n",
    "For submission of this assignment, you must do two things. \n",
    "- Download and submit the notebook `normal_estimation_depth.ipynb` to Gradescope's notebook submission section, along with your notebook for the other problems.\n",
    "- Answer the counter-example in the written section of Gradescope as a part of your `pdf` submission. \n",
    "\n",
    "We will evaluate the local functions in the notebook to see if the function behaves as we have expected. For this exercise, the rubric is as follows:\n",
    "- [4 pts] `estimate_normal_by_nearest_pixels` must be implemented correctly. \n",
    "- [2 pts] Provide a reasonable scenario that breaks the `estimate_normal_by_nearest_pixels` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xWaeAZOwlz5-"
   },
   "outputs": [],
   "source": [
    "from manipulation.exercises.clutter.test_normal import TestNormal\n",
    "from manipulation.exercises.grader import Grader \n",
    "\n",
    "Grader.grade_output([TestNormal], [locals()], 'results.json')\n",
    "Grader.print_test_results('results.json')"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "colab": {
   "collapsed_sections": [],
   "name": "normal_estimation_depth.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}